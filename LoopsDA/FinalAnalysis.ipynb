{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LoopsResultsAnalysis**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Importing and First Proccesing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "from DataCleaning import *\n",
    "from ProcessingConfig import *\n",
    "from datetime import datetime as dt\n",
    "\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_excel(cleaning_config['raw_data_path'])\n",
    "print(f'original shape: {raw_data.shape}')\n",
    "outliers_threshold = cleaning_config['filter_threshold']\n",
    "print(f\"threshold for outliers detection: {outliers_threshold}\")\n",
    "\n",
    "drop_columns(raw_data, cleaning_config['unnecessary_columns'])\n",
    "convert_types(raw_data, cleaning_config['type_conversions'])\n",
    "raw_data = filter_slow_subjects(raw_data, outliers_threshold)\n",
    "raw_data = filter_bad_subjects(raw_data, outliers_threshold)\n",
    "raw_data = drop_first_loop(raw_data)\n",
    "raw_data = only_first_line(raw_data)\n",
    "raw_data = filter_bad_trials(raw_data, threshold=0.5)\n",
    "raw_data = filter_slow_steps(raw_data, outliers_threshold)\n",
    "\n",
    "path = cleaning_config['results_path'] + f'_{dt.now().strftime(\"%d.%m.%Y_%H-%M\")}.xlsx'\n",
    "raw_data.to_excel(path)\n",
    "\n",
    "print(f'final shape: {raw_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of subjects: 17\n",
      "number of sessions: 31\n"
     ]
    }
   ],
   "source": [
    "n_subjects = raw_data['subject'].nunique()\n",
    "print(f'number of subjects: {n_subjects}')\n",
    "\n",
    "n_sessions = raw_data[['subject', 'trial_set']].drop_duplicates().shape[0]\n",
    "print(f'number of sessions: {n_sessions}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Priming Effect Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "# enveloping t_test and f_test functions\n",
    "\n",
    "def f_test(smp1, smp2, alpha):\n",
    "    f_score = smp1.std() / smp2.std()\n",
    "    df1, df2 = smp1.size - 1, smp2.size - 1\n",
    "    return stats.f.cdf(f_score, df1, df2) >= alpha\n",
    "\n",
    "def t_test_ind(smp1, smp2, alpha, alternative='two-sided'):\n",
    "    equal_var = f_test(smp1, smp2, alpha)\n",
    "    t_score, p_value = stats.ttest_ind(smp1, smp2, alternative=alternative, equal_var=equal_var)\n",
    "    \n",
    "    print(f'p_value: {p_value}')\n",
    "    if p_value <= alpha:\n",
    "        print(f'There is a significant difference between the samples! ({(1-alpha)*100}%).')\n",
    "    else:\n",
    "        print(f'It is not possible to determine whether there is an effect ({(1-alpha)*100}%).')\n",
    "    return t_score, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_response_time</th>\n",
       "      <th>mean_success_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loop_type</th>\n",
       "      <th>loop_type_switch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">for</th>\n",
       "      <th>False</th>\n",
       "      <td>3280.274038</td>\n",
       "      <td>0.973479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3265.996753</td>\n",
       "      <td>0.973144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">while</th>\n",
       "      <th>False</th>\n",
       "      <td>3585.572148</td>\n",
       "      <td>0.953600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3689.630182</td>\n",
       "      <td>0.964800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            mean_response_time  mean_success_rate\n",
       "loop_type loop_type_switch                                       \n",
       "for       False                    3280.274038           0.973479\n",
       "          True                     3265.996753           0.973144\n",
       "while     False                    3585.572148           0.953600\n",
       "          True                     3689.630182           0.964800"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean response time and success rate, group by loop type and loop switching.\n",
    "switching_diff = pd.DataFrame()\n",
    "\n",
    "switching_diff['mean_response_time'] = raw_data[raw_data['correct']].groupby(['loop_type', 'loop_type_switch'])['rt'].mean()\n",
    "switching_diff['mean_success_rate'] = raw_data.groupby(['loop_type', 'loop_type_switch'])['correct'].mean()\n",
    "\n",
    "switching_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_value: 0.5576595681879694\n",
      "It is not possible to determine whether there is an effect (95.0%).\n"
     ]
    }
   ],
   "source": [
    "# checking for priming effect on 'for' loops\n",
    "same = raw_data.loc[raw_data['correct'] & ( ~ raw_data['loop_type_switch']) & (raw_data['loop_type'] == 'for'), 'rt']\n",
    "different = raw_data.loc[raw_data['correct'] & (raw_data['loop_type_switch']) & (raw_data['loop_type'] == 'for'), 'rt']\n",
    "\n",
    "t_score, p_value = t_test_ind(different, same, alpha=alpha, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_value: 0.17272443115918634\n",
      "It is not possible to determine whether there is an effect (95.0%).\n"
     ]
    }
   ],
   "source": [
    "# checking for priming effect on 'while' loops\n",
    "same = raw_data.loc[raw_data['correct'] & ( ~ raw_data['loop_type_switch']) & (raw_data['loop_type'] == 'while'), 'rt']\n",
    "different = raw_data.loc[raw_data['correct'] & (raw_data['loop_type_switch']) & (raw_data['loop_type'] == 'while'), 'rt']\n",
    "\n",
    "t_score, p_value = t_test_ind(different, same, alpha=alpha, alternative='greater')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
