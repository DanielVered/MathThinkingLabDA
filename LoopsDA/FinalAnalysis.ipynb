{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LoopsResultsAnalysis**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Importing and First Proccesing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'loops1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m../../../msa-1/src/msa\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m../../../msa-1/scripts/loops1/preprocess_2.py\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpreprocess_2\u001b[39;00m\n\u001b[0;32m     14\u001b[0m pd\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mdisplay\u001b[39m.\u001b[39mmax_columns \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\97254\\OneDrive\\שולחן העבודה\\Projects\\MathThinkingLabDA\\LoopsDA\\../../msa-1/scripts/loops1\\preprocess_2.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[0;32m      5\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39m../../src/msa\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mloops1\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocess_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgeneral\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocess_results\u001b[39;00m \u001b[39mimport\u001b[39;00m DataMerger, col_creators\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpreprocess_1\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'loops1'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "from DataCleaning import *\n",
    "from ProcessingConfig import *\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../msa-1/src/msa')\n",
    "sys.path.append('../../../msa-1/src/msa/loops1')\n",
    "sys.path.append('../../../msa-1/scripts/loops1/preprocess_2.py')\n",
    "\n",
    "import preprocess_2\n",
    "\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape: (17408, 32)\n",
      "threshold for outliers detection: 2.25\n",
      "filter_slow_subjects: No slow subjects detected.\n",
      "filter_bad_subjects: No bad subjects detected (in terms of low success rate).\n",
      "drop_first_loop: 2134 rows were filtered out.\n",
      "only_first_line: 12081 rows were filtered out.\n",
      "filter_bad_trials: 84 bad trials were filtered (in terms of low success rate):\n",
      "   subject  trial  trial_success_rate\n",
      "0     101A      7                 0.0\n",
      "60    111A   1012                 0.0\n",
      "59    110B   1001                 0.0\n",
      "58    110B   1009                 0.0\n",
      "57    110B   1006                 0.0\n",
      "..     ...    ...                 ...\n",
      "24    107A   1002                 0.0\n",
      "23    107A   1011                 0.0\n",
      "22    107A   1007                 0.0\n",
      "30    107A   1006                 0.0\n",
      "83    111A      8                 0.0\n",
      "\n",
      "[84 rows x 3 columns]\n",
      "filter_slow_steps: 81 slow steps were filtered out.\n",
      "Here is a summary of slow steps rate per subjects: \n",
      "              slow steps rate (%)\n",
      "subject                     \n",
      "101A                    0.00\n",
      "104A                    0.64\n",
      "102A                    1.96\n",
      "106B                    1.96\n",
      "106A                    1.96\n",
      "103A                    2.38\n",
      "102B                    2.58\n",
      "101B                    3.29\n",
      "105A                    3.42\n",
      "109B                    3.87\n",
      "108A                    3.90\n",
      "107B                    4.00\n",
      "105B                    4.76\n",
      "104B                    5.11\n",
      "108B                    5.48\n",
      "109A                    5.48\n",
      "103B                    7.09\n",
      "final shape: (2524, 25)\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_excel(cleaning_config['raw_data_path'])\n",
    "print(f'original shape: {raw_data.shape}')\n",
    "outliers_threshold = cleaning_config['filter_threshold']\n",
    "print(f\"threshold for outliers detection: {outliers_threshold}\")\n",
    "\n",
    "drop_columns(raw_data, cleaning_config['unnecessary_columns'])\n",
    "convert_types(raw_data, cleaning_config['type_conversions'])\n",
    "raw_data = filter_slow_subjects(raw_data, outliers_threshold)\n",
    "raw_data = filter_bad_subjects(raw_data, outliers_threshold)\n",
    "raw_data = drop_first_loop(raw_data)\n",
    "raw_data = only_first_line(raw_data)\n",
    "raw_data = filter_bad_trials(raw_data, threshold=0.5)\n",
    "raw_data = filter_slow_steps(raw_data, outliers_threshold)\n",
    "\n",
    "path = cleaning_config['results_path'] + f'_{dt.now().strftime(\"%d.%m.%Y_%H-%M\")}.xlsx'\n",
    "raw_data.to_excel(path)\n",
    "\n",
    "print(f'final shape: {raw_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of subjects: 17\n",
      "number of sessions: 31\n"
     ]
    }
   ],
   "source": [
    "n_subjects = raw_data['subject'].nunique()\n",
    "print(f'number of subjects: {n_subjects}')\n",
    "\n",
    "n_sessions = raw_data[['subject', 'trial_set']].drop_duplicates().shape[0]\n",
    "print(f'number of sessions: {n_sessions}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Priming Effect Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "# enveloping t_test and f_test functions\n",
    "\n",
    "def f_test(smp1, smp2, alpha):\n",
    "    f_score = smp1.std() / smp2.std()\n",
    "    df1, df2 = smp1.size - 1, smp2.size - 1\n",
    "    return stats.f.cdf(f_score, df1, df2) >= alpha\n",
    "\n",
    "def t_test_ind(smp1, smp2, alpha, alternative='two-sided'):\n",
    "    equal_var = f_test(smp1, smp2, alpha)\n",
    "    t_score, p_value = stats.ttest_ind(smp1, smp2, alternative=alternative, equal_var=equal_var)\n",
    "    \n",
    "    print(f'p_value: {p_value}')\n",
    "    if p_value <= alpha:\n",
    "        print(f'There is a significant difference between the samples! ({(1-alpha)*100}%).')\n",
    "    else:\n",
    "        print(f'It is not possible to determine whether there is an effect ({(1-alpha)*100}%).')\n",
    "    return t_score, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_response_time</th>\n",
       "      <th>mean_success_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loop_type</th>\n",
       "      <th>loop_type_switch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">for</th>\n",
       "      <th>False</th>\n",
       "      <td>3280.274038</td>\n",
       "      <td>0.973479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3265.996753</td>\n",
       "      <td>0.973144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">while</th>\n",
       "      <th>False</th>\n",
       "      <td>3585.572148</td>\n",
       "      <td>0.953600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3689.630182</td>\n",
       "      <td>0.964800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            mean_response_time  mean_success_rate\n",
       "loop_type loop_type_switch                                       \n",
       "for       False                    3280.274038           0.973479\n",
       "          True                     3265.996753           0.973144\n",
       "while     False                    3585.572148           0.953600\n",
       "          True                     3689.630182           0.964800"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean response time and success rate, group by loop type and loop switching.\n",
    "switching_diff = pd.DataFrame()\n",
    "\n",
    "switching_diff['mean_response_time'] = raw_data[raw_data['correct']].groupby(['loop_type', 'loop_type_switch'])['rt'].mean()\n",
    "switching_diff['mean_success_rate'] = raw_data.groupby(['loop_type', 'loop_type_switch'])['correct'].mean()\n",
    "\n",
    "switching_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_value: 0.5576595681879694\n",
      "It is not possible to determine whether there is an effect (95.0%).\n"
     ]
    }
   ],
   "source": [
    "# checking for priming effect on 'for' loops\n",
    "same = raw_data.loc[raw_data['correct'] & ( ~ raw_data['loop_type_switch']) & (raw_data['loop_type'] == 'for'), 'rt']\n",
    "different = raw_data.loc[raw_data['correct'] & (raw_data['loop_type_switch']) & (raw_data['loop_type'] == 'for'), 'rt']\n",
    "\n",
    "t_score, p_value = t_test_ind(different, same, alpha=alpha, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_value: 0.17272443115918634\n",
      "It is not possible to determine whether there is an effect (95.0%).\n"
     ]
    }
   ],
   "source": [
    "# checking for priming effect on 'while' loops\n",
    "same = raw_data.loc[raw_data['correct'] & ( ~ raw_data['loop_type_switch']) & (raw_data['loop_type'] == 'while'), 'rt']\n",
    "different = raw_data.loc[raw_data['correct'] & (raw_data['loop_type_switch']) & (raw_data['loop_type'] == 'while'), 'rt']\n",
    "\n",
    "t_score, p_value = t_test_ind(different, same, alpha=alpha, alternative='greater')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
