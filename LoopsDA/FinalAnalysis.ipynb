{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LoopsResultsAnalysis**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Importing and First Proccesing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "from DataCleaning import *\n",
    "from ProcessingConfig import *\n",
    "from datetime import datetime as dt\n",
    "\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape: (18787, 32)\n",
      "threshold for outliers detection: 2.25\n",
      "filter_slow_subjects: No slow subjects detected.\n",
      "filter_bad_subjects: No bad subjects detected (in terms of low success rate).\n",
      "drop_first_loop: 2307 rows were filtered out.\n",
      "only_first_line: 13035 rows were filtered out.\n",
      "filter_bad_trials: No bad trials detected (in terms of low success rate).\n",
      "filter_slow_steps: 95 slow steps were filtered out.\n",
      "Here is a summary of slow steps rate per subjects: \n",
      "              slow steps rate (%)\n",
      "subject                     \n",
      "101A                    0.00\n",
      "110A                    0.00\n",
      "111A                    0.64\n",
      "104A                    0.64\n",
      "111B                    1.19\n",
      "106A                    1.96\n",
      "102A                    1.96\n",
      "106B                    1.96\n",
      "103A                    2.38\n",
      "102B                    2.58\n",
      "101B                    3.29\n",
      "105B                    3.31\n",
      "105A                    3.42\n",
      "107A                    3.57\n",
      "109B                    3.87\n",
      "108A                    3.90\n",
      "110B                    3.97\n",
      "107B                    4.00\n",
      "104B                    5.11\n",
      "108B                    5.48\n",
      "109A                    5.48\n",
      "103B                    7.09\n",
      "final shape: (3350, 25)\n",
      "number of subjects: 22\n",
      "number of sessions: 41\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_excel(cleaning_config['raw_data_path'])\n",
    "print(f'original shape: {raw_data.shape}')\n",
    "outliers_threshold = cleaning_config['filter_threshold']\n",
    "print(f\"threshold for outliers detection: {outliers_threshold}\")\n",
    "\n",
    "drop_columns(raw_data, cleaning_config['unnecessary_columns'])\n",
    "convert_types(raw_data, cleaning_config['type_conversions'])\n",
    "filtered_data = filter_slow_subjects(raw_data, outliers_threshold)\n",
    "filtered_data = filter_bad_subjects(filtered_data, outliers_threshold)\n",
    "filtered_data = drop_first_loop(filtered_data)\n",
    "filtered_data = only_first_line(filtered_data)\n",
    "filtered_data = filter_bad_trials(filtered_data, threshold=analysis_config['trials_success_rate_threshold'])\n",
    "filtered_data = filter_slow_steps(filtered_data, outliers_threshold)\n",
    "\n",
    "path = cleaning_config['results_path'] + f'_{dt.now().strftime(\"%d.%m.%Y_%H-%M\")}.xlsx'\n",
    "filtered_data.to_excel(path)\n",
    "\n",
    "print(f'final shape: {filtered_data.shape}')\n",
    "\n",
    "n_subjects = filtered_data['subject'].nunique()\n",
    "print(f'number of subjects: {n_subjects}')\n",
    "\n",
    "n_sessions = filtered_data[['subject', 'trial_set']].drop_duplicates().shape[0]\n",
    "print(f'number of sessions: {n_sessions}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. General Priming Effect Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "# enveloping t_test and f_test functions\n",
    "\n",
    "def f_test(smp1, smp2, alpha):\n",
    "    f_score = smp1.std() / smp2.std()\n",
    "    df1, df2 = smp1.size - 1, smp2.size - 1\n",
    "    return stats.f.cdf(f_score, df1, df2) >= alpha\n",
    "\n",
    "def t_test_ind(smp1, smp2, alpha, alternative='two-sided'):\n",
    "    equal_var = f_test(smp1, smp2, alpha)\n",
    "    t_score, p_value = stats.ttest_ind(smp1, smp2, alternative=alternative, equal_var=equal_var)\n",
    "    \n",
    "    print(f'p_value: {p_value}')\n",
    "    if p_value <= alpha:\n",
    "        print(f'There is a significant difference between the samples! ({(1-alpha)*100}%).')\n",
    "    else:\n",
    "        print(f'It is not possible to determine whether there is an effect ({(1-alpha)*100}%).')\n",
    "    return t_score, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_response_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loop_type</th>\n",
       "      <th>loop_type_switch</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">for</th>\n",
       "      <th>False</th>\n",
       "      <td>3222.683252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3230.482716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">while</th>\n",
       "      <th>False</th>\n",
       "      <td>3513.130818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3562.445557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            mean_response_time\n",
       "loop_type loop_type_switch                    \n",
       "for       False                    3222.683252\n",
       "          True                     3230.482716\n",
       "while     False                    3513.130818\n",
       "          True                     3562.445557"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean response time and success rate, group by loop type and loop switching.\n",
    "switching_diff_basic = pd.DataFrame()\n",
    "\n",
    "switching_diff_basic['mean_response_time'] = filtered_data[filtered_data['correct']].groupby(['loop_type', 'loop_type_switch'])['rt'].mean()\n",
    "\n",
    "switching_diff_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation between loop type switching and response time is not significant (p = 0.33)\n",
      ", with value of r = 0.017\n"
     ]
    }
   ],
   "source": [
    "# checking for a correlation between switching and response time\n",
    "r, p_val = stats.pearsonr(filtered_data['loop_type_switch'], filtered_data['rt'])\n",
    "significance = 'significant' if p_val < 0.05 else 'not significant'\n",
    "print(f\"\"\"Pearson correlation between loop type switching and response time is {significance} (p = {round(p_val, 3)})\n",
    ", with value of r = {round(r, 3)}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_value: 0.462883013839917\n",
      "It is not possible to determine whether there is an effect (95.0%).\n"
     ]
    }
   ],
   "source": [
    "# checking for priming effect on 'for' loops\n",
    "same = filtered_data.loc[filtered_data['correct'] & ( ~ filtered_data['loop_type_switch']) & (filtered_data['loop_type'] == 'for'), 'rt']\n",
    "different = filtered_data.loc[filtered_data['correct'] & (filtered_data['loop_type_switch']) & (filtered_data['loop_type'] == 'for'), 'rt']\n",
    "\n",
    "t_score, p_value = t_test_ind(different, same, alpha=alpha, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_value: 0.2977062946331592\n",
      "It is not possible to determine whether there is an effect (95.0%).\n"
     ]
    }
   ],
   "source": [
    "# checking for priming effect on 'while' loops\n",
    "same = filtered_data.loc[filtered_data['correct'] & ( ~ filtered_data['loop_type_switch']) & (filtered_data['loop_type'] == 'while'), 'rt']\n",
    "different = filtered_data.loc[filtered_data['correct'] & (filtered_data['loop_type_switch']) & (filtered_data['loop_type'] == 'while'), 'rt']\n",
    "\n",
    "t_score, p_value = t_test_ind(different, same, alpha=alpha, alternative='greater')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Different Influencors on Priming Effect**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.1. Mistake in Previous Step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_raw_data = raw_data.set_index(['subject', 'trial', 'step_num'])\n",
    "indexed_raw_data = indexed_raw_data[['correct', 'text1']]\n",
    "\n",
    "def is_prev_correct(step):\n",
    "    subject = step.loc['subject']\n",
    "    step_num = step.loc['step_num']\n",
    "    trial = step.loc['trial']\n",
    "    \n",
    "    if step_num - 1 < 0:\n",
    "        trial -= 1\n",
    "        step_num = max(indexed_raw_data.loc[(subject, trial), 'step_num'])\n",
    "    \n",
    "    return indexed_raw_data.loc[(subject, trial, step_num - 1), 'correct']\n",
    "\n",
    "filtered_data['is_prev_correct'] = filtered_data.apply(is_prev_correct, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_response_time</th>\n",
       "      <th>number_of_steps</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loop_type</th>\n",
       "      <th>loop_type_switch</th>\n",
       "      <th>is_prev_correct</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">for</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
       "      <th>False</th>\n",
       "      <td>2295.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3224.939173</td>\n",
       "      <td>822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th>False</th>\n",
       "      <td>1928.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3233.706683</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">while</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
       "      <th>False</th>\n",
       "      <td>1692.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3515.424433</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th>False</th>\n",
       "      <td>3463.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3562.570175</td>\n",
       "      <td>798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            mean_response_time  \\\n",
       "loop_type loop_type_switch is_prev_correct                       \n",
       "for       False            False                   2295.500000   \n",
       "                           True                    3224.939173   \n",
       "          True             False                   1928.000000   \n",
       "                           True                    3233.706683   \n",
       "while     False            False                   1692.000000   \n",
       "                           True                    3515.424433   \n",
       "          True             False                   3463.000000   \n",
       "                           True                    3562.570175   \n",
       "\n",
       "                                            number_of_steps  \n",
       "loop_type loop_type_switch is_prev_correct                   \n",
       "for       False            False                          2  \n",
       "                           True                         822  \n",
       "          True             False                          2  \n",
       "                           True                         808  \n",
       "while     False            False                          1  \n",
       "                           True                         794  \n",
       "          True             False                          1  \n",
       "                           True                         798  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean response time and success rate, group by loop type and loop switching.\n",
    "switching_diff_prev_correct = pd.DataFrame()\n",
    "\n",
    "switching_diff_prev_correct['mean_response_time'] = filtered_data[filtered_data['correct']].groupby(['loop_type', 'loop_type_switch', 'is_prev_correct'])['rt'].mean()\n",
    "switching_diff_prev_correct['number_of_steps'] = filtered_data[filtered_data['correct']].groupby(['loop_type', 'loop_type_switch', 'is_prev_correct'])['step_num'].count()\n",
    "\n",
    "switching_diff_prev_correct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
