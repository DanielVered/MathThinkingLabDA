{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LoopsResultsAnalysis**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Importing and First Proccesing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from DataCleaning import *\n",
    "from ProcessingConfig import *\n",
    "\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape: (13294, 32)\n",
      "-- drop_first_loop: 1630 rows were filtered out.\n",
      "-- drop_first_line: 2437 rows were filtered out.\n",
      "-- filter_trail_outliers: 721 rows were filtered out.\n",
      "-- filter_step_outliers: 242 rows were filtered out.\n",
      "final shape: (8264, 26)\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_excel(cleaning_config['raw_data_path'])\n",
    "print(f'original shape: {raw_data.shape}')\n",
    "raw_data = clean_data(raw_data)\n",
    "print(f'final shape: {raw_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of subjects: 15\n",
      "number of sessions: 29\n"
     ]
    }
   ],
   "source": [
    "n_subjects = raw_data['subject'].nunique()\n",
    "print(f'number of subjects: {n_subjects}')\n",
    "\n",
    "n_sessions = raw_data[['subject', 'trial_set']].drop_duplicates().shape[0]\n",
    "print(f'number of sessions: {n_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enveloping t_test and f_test functions\n",
    "\n",
    "def f_test(smp1, smp2, alpha):\n",
    "    f_score = smp1.std() / smp2.std()\n",
    "    df1, df2 = smp1.size - 1, smp2.size - 1\n",
    "    return stats.f.cdf(f_score, df1, df2) >= alpha\n",
    "\n",
    "def t_test_ind(smp1, smp2, alpha, alternative='two-sided'):\n",
    "    equal_var = f_test(smp1, smp2, alpha)\n",
    "    t_score, p_value = stats.ttest_ind(smp1, smp2, alternative=alternative, equal_var=equal_var)\n",
    "    \n",
    "    print(f'p_value: {p_value}')\n",
    "    if p_value <= alpha:\n",
    "        print('There is a difference between the samples!')\n",
    "    else:\n",
    "        print('It is not possible to determine whether there is an effect.')\n",
    "    return t_score, p_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Priming Effect Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_response_time</th>\n",
       "      <th>mean_success_rate</th>\n",
       "      <th>loop_end_mean_response_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loop_type</th>\n",
       "      <th>loop_type_switch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">for</th>\n",
       "      <th>False</th>\n",
       "      <td>1304.817951</td>\n",
       "      <td>0.977205</td>\n",
       "      <td>591.438721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1339.163618</td>\n",
       "      <td>0.981546</td>\n",
       "      <td>583.686941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">while</th>\n",
       "      <th>False</th>\n",
       "      <td>1567.088924</td>\n",
       "      <td>0.978626</td>\n",
       "      <td>813.898551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1574.004692</td>\n",
       "      <td>0.975585</td>\n",
       "      <td>788.949550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            mean_response_time  mean_success_rate  \\\n",
       "loop_type loop_type_switch                                          \n",
       "for       False                    1304.817951           0.977205   \n",
       "          True                     1339.163618           0.981546   \n",
       "while     False                    1567.088924           0.978626   \n",
       "          True                     1574.004692           0.975585   \n",
       "\n",
       "                            loop_end_mean_response_time  \n",
       "loop_type loop_type_switch                               \n",
       "for       False                              591.438721  \n",
       "          True                               583.686941  \n",
       "while     False                              813.898551  \n",
       "          True                               788.949550  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "switching_diff = pd.DataFrame()\n",
    "\n",
    "# mean response time and success rate, group by loop type and loop switching.\n",
    "switching_diff['mean_response_time'] = raw_data[raw_data['correct']].groupby(['loop_type', 'loop_type_switch'])['rt'].mean()\n",
    "switching_diff['mean_success_rate'] = raw_data.groupby(['loop_type', 'loop_type_switch'])['correct'].mean()\n",
    "\n",
    "# loop ending response time, group by loop type and loop switching.\n",
    "loop_end_mask = (raw_data['response_needed']) & (raw_data['expected_response'].isnull()) & (raw_data['correct'])\n",
    "switching_diff['loop_end_mean_response_time'] = raw_data.loc[loop_end_mask].groupby(['loop_type', 'loop_type_switch'])['rt'].mean()\n",
    "\n",
    "switching_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_value: 0.18413260693230632\n",
      "It is not possible to determine whether there is an effect.\n"
     ]
    }
   ],
   "source": [
    "# checking for priming effect on 'for' loops\n",
    "same = raw_data.loc[raw_data['correct'] & ( ~ raw_data['loop_type_switch']) & (raw_data['loop_type'] == 'for'), 'rt']\n",
    "different = raw_data.loc[raw_data['correct'] & (raw_data['loop_type_switch']) & (raw_data['loop_type'] == 'for'), 'rt']\n",
    "\n",
    "t_score, p_value = t_test_ind(different, same, alpha=alpha, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_value: 0.43659566007509937\n",
      "It is not possible to determine whether there is an effect.\n"
     ]
    }
   ],
   "source": [
    "# checking for priming effect on 'while' loops\n",
    "same = raw_data.loc[raw_data['correct'] & ( ~ raw_data['loop_type_switch']) & (raw_data['loop_type'] == 'while'), 'rt']\n",
    "different = raw_data.loc[raw_data['correct'] & (raw_data['loop_type_switch']) & (raw_data['loop_type'] == 'while'), 'rt']\n",
    "\n",
    "t_score, p_value = t_test_ind(different, same, alpha=alpha, alternative='greater')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Difference Between Loop Types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_value: 3.915993895607329e-18\n",
      "There is a difference between the samples!\n"
     ]
    }
   ],
   "source": [
    "# general difference between response time in 'while' loops and 'for' loops\n",
    "for_rt = raw_data.loc[raw_data['correct'] & (raw_data['loop_type'] == 'for'), 'rt']\n",
    "while_rt = raw_data.loc[raw_data['correct'] & (raw_data['loop_type'] == 'while'), 'rt']\n",
    "\n",
    "t_score, p_value = t_test_ind(while_rt, for_rt, alpha=alpha, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_value: 2.5893518354792905e-11\n",
      "There is a difference between the samples!\n"
     ]
    }
   ],
   "source": [
    "# difference between 'end loop' step response time in 'while' loops and 'for' loops\n",
    "for_end_loop_rt = raw_data.loc[loop_end_mask & (raw_data['loop_type'] == 'for'), 'rt']\n",
    "while_end_loop_rt = raw_data.loc[loop_end_mask & (raw_data['loop_type'] == 'while'), 'rt']\n",
    "\n",
    "t_score, p_value = t_test_ind(while_end_loop_rt, for_end_loop_rt, alpha=alpha, alternative='greater')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
