{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LoopsResultsAnalysis**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Importing and First Proccesing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from DataCleaning import *\n",
    "from ProcessingConfig import *\n",
    "\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape: (13294, 32)\n",
      "threshold for outliers detection: 2.25\n",
      "-- drop_first_loop: 1630 rows were filtered out.\n",
      "-- filter_trial_outliers: 211 rows were filtered out.\n",
      "-- filter_step_outliers: 275 rows were filtered out.\n",
      "final shape: (11178, 26)\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_excel(cleaning_config['raw_data_path'])\n",
    "print(f'original shape: {raw_data.shape}')\n",
    "print(f\"threshold for outliers detection: {cleaning_config['filter_threshold']}\")\n",
    "raw_data = clean_data(raw_data)\n",
    "print(f'final shape: {raw_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of subjects: 15\n",
      "number of sessions: 29\n"
     ]
    }
   ],
   "source": [
    "n_subjects = raw_data['subject'].nunique()\n",
    "print(f'number of subjects: {n_subjects}')\n",
    "\n",
    "n_sessions = raw_data[['subject', 'trial_set']].drop_duplicates().shape[0]\n",
    "print(f'number of sessions: {n_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enveloping t_test and f_test functions\n",
    "\n",
    "def f_test(smp1, smp2, alpha):\n",
    "    f_score = smp1.std() / smp2.std()\n",
    "    df1, df2 = smp1.size - 1, smp2.size - 1\n",
    "    return stats.f.cdf(f_score, df1, df2) >= alpha\n",
    "\n",
    "def t_test_ind(smp1, smp2, alpha, alternative='two-sided'):\n",
    "    equal_var = f_test(smp1, smp2, alpha)\n",
    "    t_score, p_value = stats.ttest_ind(smp1, smp2, alternative=alternative, equal_var=equal_var)\n",
    "    \n",
    "    print(f'p_value: {p_value}')\n",
    "    if p_value <= alpha:\n",
    "        print(f'There is a significant difference between the samples! ({(1-alpha)*100}%).')\n",
    "    else:\n",
    "        print(f'It is not possible to determine whether there is an effect ({(1-alpha)*100}%).')\n",
    "    return t_score, p_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Priming Effect Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop_priming_data has 2250 rows.\n"
     ]
    }
   ],
   "source": [
    "# note that 'loop_step' is an id of each step in the loop, ranging 0-len(loop).\n",
    "only_first_line = raw_data['loop_step'] == 0\n",
    "loop_priming_data = raw_data[only_first_line].copy()\n",
    "\n",
    "loop_priming_data.to_excel(r'Results\\LoopPrimingData.xlsx')\n",
    "\n",
    "print(f'loop_priming_data has {loop_priming_data.shape[0]} rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_response_time</th>\n",
       "      <th>mean_success_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loop_type</th>\n",
       "      <th>loop_type_switch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">for</th>\n",
       "      <th>False</th>\n",
       "      <td>3135.508897</td>\n",
       "      <td>0.980803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3169.817204</td>\n",
       "      <td>0.977233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">while</th>\n",
       "      <th>False</th>\n",
       "      <td>3402.600000</td>\n",
       "      <td>0.965704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3480.482243</td>\n",
       "      <td>0.969203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            mean_response_time  mean_success_rate\n",
       "loop_type loop_type_switch                                       \n",
       "for       False                    3135.508897           0.980803\n",
       "          True                     3169.817204           0.977233\n",
       "while     False                    3402.600000           0.965704\n",
       "          True                     3480.482243           0.969203"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean response time and success rate, group by loop type and loop switching.\n",
    "switching_diff = pd.DataFrame()\n",
    "\n",
    "switching_diff['mean_response_time'] = loop_priming_data[loop_priming_data['correct']].groupby(['loop_type', 'loop_type_switch'])['rt'].mean()\n",
    "switching_diff['mean_success_rate'] = loop_priming_data.groupby(['loop_type', 'loop_type_switch'])['correct'].mean()\n",
    "\n",
    "switching_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_value: 0.35478490049617406\n",
      "It is not possible to determine whether there is an effect (95.0%).\n"
     ]
    }
   ],
   "source": [
    "# checking for priming effect on 'for' loops\n",
    "same = loop_priming_data.loc[loop_priming_data['correct'] & ( ~ loop_priming_data['loop_type_switch']) & (loop_priming_data['loop_type'] == 'for'), 'rt']\n",
    "different = loop_priming_data.loc[loop_priming_data['correct'] & (loop_priming_data['loop_type_switch']) & (loop_priming_data['loop_type'] == 'for'), 'rt']\n",
    "\n",
    "t_score, p_value = t_test_ind(different, same, alpha=alpha, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_value: 0.22297437329252862\n",
      "It is not possible to determine whether there is an effect (95.0%).\n"
     ]
    }
   ],
   "source": [
    "# checking for priming effect on 'while' loops\n",
    "same = loop_priming_data.loc[loop_priming_data['correct'] & ( ~ loop_priming_data['loop_type_switch']) & (loop_priming_data['loop_type'] == 'while'), 'rt']\n",
    "different = loop_priming_data.loc[loop_priming_data['correct'] & (loop_priming_data['loop_type_switch']) & (loop_priming_data['loop_type'] == 'while'), 'rt']\n",
    "\n",
    "t_score, p_value = t_test_ind(different, same, alpha=alpha, alternative='greater')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Difference Between Loop Types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loops_data = raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_value: 6.062364677586016e-16\n",
      "There is a significant difference between the samples! (95.0%).\n"
     ]
    }
   ],
   "source": [
    "# general difference between response time in 'while' loops versus 'for' loops\n",
    "for_rt = all_loops_data.loc[all_loops_data['correct'] & (all_loops_data['loop_type'] == 'for'), 'rt']\n",
    "while_rt = all_loops_data.loc[all_loops_data['correct'] & (all_loops_data['loop_type'] == 'while'), 'rt']\n",
    "\n",
    "t_score, p_value = t_test_ind(while_rt, for_rt, alpha=alpha, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_value: 4.907838664353287e-10\n",
      "There is a significant difference between the samples! (95.0%).\n"
     ]
    }
   ],
   "source": [
    "# difference between 'end loop' step response time in 'while' loops versus 'for' loops\n",
    "loop_end_mask = (all_loops_data['response_needed']) & (all_loops_data['expected_response'].isnull()) & (all_loops_data['correct'])\n",
    "\n",
    "for_end_loop_rt = all_loops_data.loc[loop_end_mask & (all_loops_data['loop_type'] == 'for'), 'rt']\n",
    "while_end_loop_rt = all_loops_data.loc[loop_end_mask & (all_loops_data['loop_type'] == 'while'), 'rt']\n",
    "\n",
    "t_score, p_value = t_test_ind(while_end_loop_rt, for_end_loop_rt, alpha=alpha, alternative='greater')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
